{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HillaryMulyadi/Assignment-1/blob/master/codecollab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "bBzCATUyUJ-s"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "path = Path('Assignment1-Dataset')\n",
        "zipfile.ZipFile(f'{path}.zip').extractall(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "rMseYpQRUJ-t"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "import pdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0bLF1LjUJ-t"
      },
      "source": [
        "# Data Exploration and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Y1B9km-rUJ-u"
      },
      "outputs": [],
      "source": [
        "raw_train_data = np.load(path/path/'train_data.npy')\n",
        "raw_train_label = np.load(path/path/'train_label.npy')\n",
        "raw_test_data = np.load(path/path/'test_data.npy')\n",
        "raw_test_label = np.load(path/path/'test_label.npy')\n",
        "\n",
        "train_data_df = pd.DataFrame(raw_train_data)\n",
        "train_label_df = pd.DataFrame(raw_train_label)\n",
        "test_data_df = pd.DataFrame(raw_test_data)\n",
        "test_df_label = pd.DataFrame(raw_test_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "8RB9QUcmUJ-u",
        "outputId": "8e62fad2-e4f9-4db7-f1e7-cc78ffe41866"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0          1         2         3         4         5         6    \\\n",
              "0  -6.401018   2.729039  1.501711 -2.953333 -4.452582  0.647150  0.568989   \n",
              "1   0.829783  -0.949943  6.003753  1.504931 -1.368500  1.225687  0.606882   \n",
              "2   7.730200 -11.522102 -2.753621  2.333595 -1.584409 -2.272213 -0.610438   \n",
              "3 -10.347817   0.010738  1.101019 -1.304540 -1.594870  0.867600  0.194107   \n",
              "4  -2.625651  -4.969240  1.034585  3.306459  1.261683  0.031241  5.655493   \n",
              "\n",
              "        7         8         9    ...       118       119       120       121  \\\n",
              "0  0.092877  3.451771  1.168442  ...  0.031096 -0.568329  0.078852 -0.516114   \n",
              "1 -0.523086  2.584150  2.565564  ... -0.337097  0.064675  0.654332  0.340445   \n",
              "2 -1.361358 -0.730908 -1.125914  ... -0.182330  0.048012  0.008707 -0.028796   \n",
              "3  0.232392  1.467262 -0.359152  ...  0.216759 -0.097580 -0.080088  0.074279   \n",
              "4  1.426761  3.918136 -1.955221  ... -0.520018  0.045069  0.391479 -0.228605   \n",
              "\n",
              "        122       123       124       125       126       127  \n",
              "0 -0.533383  0.182485 -0.116055  0.229334 -0.153583  0.544041  \n",
              "1  0.173168 -0.093886 -0.232945  0.043194 -0.015716 -0.289076  \n",
              "2 -0.267608  0.008759 -0.206363  0.014587 -0.355830  0.184288  \n",
              "3  0.280708 -0.017641 -0.328347 -0.054606  0.104805  0.031092  \n",
              "4 -0.688175  0.614231 -0.200600 -0.128712  0.125463  0.117314  \n",
              "\n",
              "[5 rows x 128 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e482bb16-1ec0-4653-84f1-e4b5eea15376\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-6.401018</td>\n",
              "      <td>2.729039</td>\n",
              "      <td>1.501711</td>\n",
              "      <td>-2.953333</td>\n",
              "      <td>-4.452582</td>\n",
              "      <td>0.647150</td>\n",
              "      <td>0.568989</td>\n",
              "      <td>0.092877</td>\n",
              "      <td>3.451771</td>\n",
              "      <td>1.168442</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031096</td>\n",
              "      <td>-0.568329</td>\n",
              "      <td>0.078852</td>\n",
              "      <td>-0.516114</td>\n",
              "      <td>-0.533383</td>\n",
              "      <td>0.182485</td>\n",
              "      <td>-0.116055</td>\n",
              "      <td>0.229334</td>\n",
              "      <td>-0.153583</td>\n",
              "      <td>0.544041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.829783</td>\n",
              "      <td>-0.949943</td>\n",
              "      <td>6.003753</td>\n",
              "      <td>1.504931</td>\n",
              "      <td>-1.368500</td>\n",
              "      <td>1.225687</td>\n",
              "      <td>0.606882</td>\n",
              "      <td>-0.523086</td>\n",
              "      <td>2.584150</td>\n",
              "      <td>2.565564</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.337097</td>\n",
              "      <td>0.064675</td>\n",
              "      <td>0.654332</td>\n",
              "      <td>0.340445</td>\n",
              "      <td>0.173168</td>\n",
              "      <td>-0.093886</td>\n",
              "      <td>-0.232945</td>\n",
              "      <td>0.043194</td>\n",
              "      <td>-0.015716</td>\n",
              "      <td>-0.289076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.730200</td>\n",
              "      <td>-11.522102</td>\n",
              "      <td>-2.753621</td>\n",
              "      <td>2.333595</td>\n",
              "      <td>-1.584409</td>\n",
              "      <td>-2.272213</td>\n",
              "      <td>-0.610438</td>\n",
              "      <td>-1.361358</td>\n",
              "      <td>-0.730908</td>\n",
              "      <td>-1.125914</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.182330</td>\n",
              "      <td>0.048012</td>\n",
              "      <td>0.008707</td>\n",
              "      <td>-0.028796</td>\n",
              "      <td>-0.267608</td>\n",
              "      <td>0.008759</td>\n",
              "      <td>-0.206363</td>\n",
              "      <td>0.014587</td>\n",
              "      <td>-0.355830</td>\n",
              "      <td>0.184288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-10.347817</td>\n",
              "      <td>0.010738</td>\n",
              "      <td>1.101019</td>\n",
              "      <td>-1.304540</td>\n",
              "      <td>-1.594870</td>\n",
              "      <td>0.867600</td>\n",
              "      <td>0.194107</td>\n",
              "      <td>0.232392</td>\n",
              "      <td>1.467262</td>\n",
              "      <td>-0.359152</td>\n",
              "      <td>...</td>\n",
              "      <td>0.216759</td>\n",
              "      <td>-0.097580</td>\n",
              "      <td>-0.080088</td>\n",
              "      <td>0.074279</td>\n",
              "      <td>0.280708</td>\n",
              "      <td>-0.017641</td>\n",
              "      <td>-0.328347</td>\n",
              "      <td>-0.054606</td>\n",
              "      <td>0.104805</td>\n",
              "      <td>0.031092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-2.625651</td>\n",
              "      <td>-4.969240</td>\n",
              "      <td>1.034585</td>\n",
              "      <td>3.306459</td>\n",
              "      <td>1.261683</td>\n",
              "      <td>0.031241</td>\n",
              "      <td>5.655493</td>\n",
              "      <td>1.426761</td>\n",
              "      <td>3.918136</td>\n",
              "      <td>-1.955221</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.520018</td>\n",
              "      <td>0.045069</td>\n",
              "      <td>0.391479</td>\n",
              "      <td>-0.228605</td>\n",
              "      <td>-0.688175</td>\n",
              "      <td>0.614231</td>\n",
              "      <td>-0.200600</td>\n",
              "      <td>-0.128712</td>\n",
              "      <td>0.125463</td>\n",
              "      <td>0.117314</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 128 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e482bb16-1ec0-4653-84f1-e4b5eea15376')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e482bb16-1ec0-4653-84f1-e4b5eea15376 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e482bb16-1ec0-4653-84f1-e4b5eea15376');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-85c2a8f5-74a3-4373-bcc1-e218f9398284\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-85c2a8f5-74a3-4373-bcc1-e218f9398284')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-85c2a8f5-74a3-4373-bcc1-e218f9398284 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data_df"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "train_data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UNOAMYNUJ-v",
        "outputId": "9976648c-4e94-41c1-a0f2-649d54fc9df6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data has shape: (50000, 128)\n",
            "Test data has shape: (10000, 128)\n"
          ]
        }
      ],
      "source": [
        "print(\"Train data has shape:\", train_data_df.shape)\n",
        "print(\"Test data has shape:\", test_data_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "7-8Npb6sUJ-w",
        "outputId": "a1069225-4356-4347-9245-78c6b4a07151"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0         1         2         3         4         5         6    \\\n",
              "0 -3.479671  0.906426  1.251956  3.164191 -1.918240  1.659476 -0.068083   \n",
              "1  9.943158 -9.580553  5.068578 -2.961200  1.110012 -0.266616 -1.147632   \n",
              "2  4.704300 -8.837206  4.109285  1.030721  0.204448 -0.911759  5.313861   \n",
              "3  8.046408 -3.812435  6.268061 -0.799734 -0.160306  4.558274  0.988285   \n",
              "4 -5.254615  4.320979  1.844344 -0.784487  0.386743  0.410722  0.666861   \n",
              "\n",
              "        7         8         9    ...       118       119       120       121  \\\n",
              "0  0.160349 -0.472169 -0.182596  ...  0.339111 -0.077960  0.224511  0.065051   \n",
              "1 -3.261594  1.486868 -3.944965  ... -0.316570  0.213633  0.004196 -0.018760   \n",
              "2  1.123139  1.150991  0.448419  ... -0.140834 -0.263962  0.180676 -0.571248   \n",
              "3  0.892768 -1.147928  0.752415  ... -0.159262 -0.050812  0.671486 -0.072334   \n",
              "4  1.029134  0.203599  0.083327  ...  0.194132  0.341377 -0.181054  0.213460   \n",
              "\n",
              "        122       123       124       125       126       127  \n",
              "0 -0.096021 -0.195548 -0.597775  0.861874  0.631729  0.260908  \n",
              "1 -0.591259  0.538358 -0.685603  0.163248 -0.318575 -0.267055  \n",
              "2  0.200106  0.007189 -0.177507  0.055749  0.265140  0.167866  \n",
              "3  0.377145 -0.376418 -0.495225  0.070410 -0.494369  0.006503  \n",
              "4 -0.109972 -0.040297 -0.082909  0.235958 -0.526390 -0.010561  \n",
              "\n",
              "[5 rows x 128 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-128d272c-c8e6-4907-a595-8e84f701790a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-3.479671</td>\n",
              "      <td>0.906426</td>\n",
              "      <td>1.251956</td>\n",
              "      <td>3.164191</td>\n",
              "      <td>-1.918240</td>\n",
              "      <td>1.659476</td>\n",
              "      <td>-0.068083</td>\n",
              "      <td>0.160349</td>\n",
              "      <td>-0.472169</td>\n",
              "      <td>-0.182596</td>\n",
              "      <td>...</td>\n",
              "      <td>0.339111</td>\n",
              "      <td>-0.077960</td>\n",
              "      <td>0.224511</td>\n",
              "      <td>0.065051</td>\n",
              "      <td>-0.096021</td>\n",
              "      <td>-0.195548</td>\n",
              "      <td>-0.597775</td>\n",
              "      <td>0.861874</td>\n",
              "      <td>0.631729</td>\n",
              "      <td>0.260908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.943158</td>\n",
              "      <td>-9.580553</td>\n",
              "      <td>5.068578</td>\n",
              "      <td>-2.961200</td>\n",
              "      <td>1.110012</td>\n",
              "      <td>-0.266616</td>\n",
              "      <td>-1.147632</td>\n",
              "      <td>-3.261594</td>\n",
              "      <td>1.486868</td>\n",
              "      <td>-3.944965</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.316570</td>\n",
              "      <td>0.213633</td>\n",
              "      <td>0.004196</td>\n",
              "      <td>-0.018760</td>\n",
              "      <td>-0.591259</td>\n",
              "      <td>0.538358</td>\n",
              "      <td>-0.685603</td>\n",
              "      <td>0.163248</td>\n",
              "      <td>-0.318575</td>\n",
              "      <td>-0.267055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.704300</td>\n",
              "      <td>-8.837206</td>\n",
              "      <td>4.109285</td>\n",
              "      <td>1.030721</td>\n",
              "      <td>0.204448</td>\n",
              "      <td>-0.911759</td>\n",
              "      <td>5.313861</td>\n",
              "      <td>1.123139</td>\n",
              "      <td>1.150991</td>\n",
              "      <td>0.448419</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.140834</td>\n",
              "      <td>-0.263962</td>\n",
              "      <td>0.180676</td>\n",
              "      <td>-0.571248</td>\n",
              "      <td>0.200106</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>-0.177507</td>\n",
              "      <td>0.055749</td>\n",
              "      <td>0.265140</td>\n",
              "      <td>0.167866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.046408</td>\n",
              "      <td>-3.812435</td>\n",
              "      <td>6.268061</td>\n",
              "      <td>-0.799734</td>\n",
              "      <td>-0.160306</td>\n",
              "      <td>4.558274</td>\n",
              "      <td>0.988285</td>\n",
              "      <td>0.892768</td>\n",
              "      <td>-1.147928</td>\n",
              "      <td>0.752415</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.159262</td>\n",
              "      <td>-0.050812</td>\n",
              "      <td>0.671486</td>\n",
              "      <td>-0.072334</td>\n",
              "      <td>0.377145</td>\n",
              "      <td>-0.376418</td>\n",
              "      <td>-0.495225</td>\n",
              "      <td>0.070410</td>\n",
              "      <td>-0.494369</td>\n",
              "      <td>0.006503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-5.254615</td>\n",
              "      <td>4.320979</td>\n",
              "      <td>1.844344</td>\n",
              "      <td>-0.784487</td>\n",
              "      <td>0.386743</td>\n",
              "      <td>0.410722</td>\n",
              "      <td>0.666861</td>\n",
              "      <td>1.029134</td>\n",
              "      <td>0.203599</td>\n",
              "      <td>0.083327</td>\n",
              "      <td>...</td>\n",
              "      <td>0.194132</td>\n",
              "      <td>0.341377</td>\n",
              "      <td>-0.181054</td>\n",
              "      <td>0.213460</td>\n",
              "      <td>-0.109972</td>\n",
              "      <td>-0.040297</td>\n",
              "      <td>-0.082909</td>\n",
              "      <td>0.235958</td>\n",
              "      <td>-0.526390</td>\n",
              "      <td>-0.010561</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 128 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-128d272c-c8e6-4907-a595-8e84f701790a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-128d272c-c8e6-4907-a595-8e84f701790a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-128d272c-c8e6-4907-a595-8e84f701790a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a8ae113b-86d8-4804-ab13-b35e7d3aa54c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a8ae113b-86d8-4804-ab13-b35e7d3aa54c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a8ae113b-86d8-4804-ab13-b35e7d3aa54c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data_df"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "test_data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "443H6DjeUJ-x",
        "outputId": "19239692-52ba-44c7-f584-444e9e18b41e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data has shape: (50000, 128)\n",
            "Test data has shape: (10000, 128)\n"
          ]
        }
      ],
      "source": [
        "print(\"Train data has shape:\", train_data_df.shape)\n",
        "print(\"Test data has shape:\", test_data_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEhtFLFSUJ-x"
      },
      "source": [
        "# Create Activation class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "5j55sFH0UJ-x"
      },
      "outputs": [],
      "source": [
        "# Incorporating ReLU\n",
        "class Activation(object):\n",
        "    def __tanh(self, x):\n",
        "        return np.tanh(x)\n",
        "\n",
        "    def __tanh_deriv(self, a):\n",
        "        # a = np.tanh(x)\n",
        "        return 1.0 - a**2\n",
        "\n",
        "    def __logistic(self, x):\n",
        "        return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "    def __logistic_deriv(self, a):\n",
        "        # a = logistic(x)\n",
        "        return  a * (1 - a)\n",
        "\n",
        "    def __relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def __relu_deriv(self, a):\n",
        "        return 1 if a > 0 else 0\n",
        "\n",
        "    def __softmax(self, x):\n",
        "        exps = np.exp(x)\n",
        "        exp_sums = np.sum(exps, axis=1, keepdims=True)\n",
        "        return exps / exp_sums\n",
        "\n",
        "    def __softmax_deriv(self, a, y):\n",
        "        return a - y\n",
        "\n",
        "    def __init__(self, activation='tanh', y=None):\n",
        "        if activation == 'logistic':\n",
        "            self.f = self.__logistic\n",
        "            self.f_deriv = self.__logistic_deriv\n",
        "        elif activation == 'tanh':\n",
        "            self.f = self.__tanh\n",
        "            self.f_deriv = self.__tanh_deriv\n",
        "        elif activation == 'relu':\n",
        "            self.f = self.__relu\n",
        "            self.f_deriv = self.__relu_deriv\n",
        "        elif activation == 'softmax':\n",
        "            self.f = self.__softmax\n",
        "            self.f_deriv = self.__softmax_deriv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbCMeVEqUJ-x"
      },
      "source": [
        "# Define Hidden Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cyuzic8bUJ-x"
      },
      "source": [
        "Designed to be able to take more than one hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "SJpzMDrsUJ-y"
      },
      "outputs": [],
      "source": [
        "class HiddenLayer(object):\n",
        "    def __init__(self, n_in, n_out, activation_last_layer='tanh', activation='tanh', W=None, b=None):\n",
        "\n",
        "        # Attribute: Activation Function\n",
        "        self.input = None # provide a default value for the input attribute when an instance of the HiddenLayer class is created\n",
        "        self.activation = Activation(activation).f\n",
        "\n",
        "        # Attribute: activation deriv of last layer\n",
        "        self.activation_deriv = None\n",
        "        if activation_last_layer: # this is saying: if it is not the input layer\n",
        "            self.activation_deriv = Activation(activation_last_layer).f_deriv # this is calling the specific function found in Activation class\n",
        "\n",
        "        # Attribute: Weight\n",
        "        self.W = np.random.uniform(\n",
        "                low = -np.sqrt(6. / (n_in + n_out)),\n",
        "                high = np.sqrt(6. / (n_in + n_out)),\n",
        "                size = (n_in, n_out)\n",
        "        )\n",
        "\n",
        "        # Attribute: Bias\n",
        "        # we set the size of bias as the size of output dimension\n",
        "        self.b = np.zeros(n_out,)\n",
        "\n",
        "        # Attribute: Gradient of Weight and Gradient of Bias\n",
        "        # we set the size of weight gradient as the size of the weight matrix\n",
        "        self.grad_W = np.zeros(self.W.shape)\n",
        "        self.grad_b = np.zeros(self.b.shape)\n",
        "\n",
        "\n",
        "    # The forward and backward propagation (in the hidden layer level) for each training epoch\n",
        "    def forward(self, input):\n",
        "\n",
        "        lin_output = np.dot(input, self.W) + self.b # this is netk and netj\n",
        "        self.output = (\n",
        "            lin_output if self.activation is None # self.activation is None in the 1st layer because the 1st layer is the input layer; in the 1st layer, the output is simply the dot product --> (input @ w) + b\n",
        "            else self.activation(lin_output) # in the 2nd layer and 3rd layer, we apply activation function to the output we just calculated (lin_output)\n",
        "        )\n",
        "        self.input = input\n",
        "        return self.output\n",
        "\n",
        "\n",
        "    def backward(self, delta, output_layer = False): # delta is the gradient of lin_output; result of previous numerical layers gradients\n",
        "        WEIGHT_DECAY = 0.01\n",
        "        # Calculate gradient of the loss with respect to the weights W in that layer\n",
        "        # This incorporates weight decay!\n",
        "        self.grad_W = np.atleast_2d(self.input).T.dot(np.atleast_2d(delta)) + (WEIGHT_DECAY * self.W) # basically delta @ input | atleast_2d --> just used to transpose input into dimension that is larger than 2d; this is basically gradient multiplied by self.input which is either netk (y2w2 + y2w2 + y3w3) or netj (x1w1 + x2w2)\n",
        "        self.grad_b = delta\n",
        "\n",
        "        # In the output layer, we already calculated delta --> delta = -2*error*activation_deriv(y_hat); this delta is being passed in as an argument in the backward(delta), so the code here is actually updating the next delta which is for the hidden layer (which is the second layer);\n",
        "        # in the input layer, the activation_last_layer is None because the input layer does not have activation function therefore self.activation_deriv is None therefore this code below won't be run and delta is not updated in the first layer\n",
        "        if self.activation_deriv:\n",
        "            delta = delta.dot(self.W.T) * self.activation_deriv(self.input) # here self.input refers to yj and zk --> the activation function outputs f(netj) and f(netk)\n",
        "\n",
        "        return delta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r67azl9rUJ-y"
      },
      "source": [
        "# Define the MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghbnjvFMUJ-y"
      },
      "source": [
        "The tutorial uses Stochasic GD but the assignment requires Momentum in SGD AND Mini-batch training.\n",
        "The tutorial also uses MSE as loss function but the assignment requires softmax and cross-entropy loss.\n",
        "Also requires:\n",
        "- Batch Normalization\n",
        "- Dropout\n",
        "- Weight Decay\n",
        "- maybe Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVUbV7rrUJ-y"
      },
      "source": [
        "## Make one-hot vector for each class (0-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxY-Z_sBUJ-y",
        "outputId": "1ad83b96-23a2-41f6-d2f5-afb8eeb0e0f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "# y-train\n",
        "y_train_one_hot = pd.get_dummies(train_label_df[0]).astype(int)\n",
        "y_train_one_hot = y_train_one_hot.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoiOdjOaUJ-y"
      },
      "source": [
        "# Mini-batch Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "-AfHQr-jUJ-y"
      },
      "outputs": [],
      "source": [
        "# define a function that returns inputs and targets of batches\n",
        "def random_mini_batches(inputs, targets, batchsize, shuffle=False):\n",
        "    assert inputs.shape[0] == targets.shape[0]\n",
        "    targets = pd.DataFrame(targets)\n",
        "    if shuffle:\n",
        "        indices = np.arange(inputs.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "    for start_idx in range(0, inputs.shape[0], batchsize):\n",
        "        if shuffle:\n",
        "            batch_indices = indices[start_idx:start_idx + batchsize]\n",
        "        else:\n",
        "            batch_indices = slice(start_idx, start_idx + batchsize)\n",
        "        yield inputs.iloc[batch_indices], targets.iloc[batch_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "9iwDG3kVUJ-y"
      },
      "outputs": [],
      "source": [
        "class MLP:\n",
        "\n",
        "    # for initialization, the code will create all layers automatically based on the provided parameters.\n",
        "    def __init__(self, layers, activation=[None, None, None, None, None]):\n",
        "        # initialize layers\n",
        "        self.layers = []\n",
        "        self.activation = activation\n",
        "\n",
        "        for i in range(len(layers)-1):\n",
        "            self.layers.append(HiddenLayer(layers[i],layers[i+1],activation[i],activation[i+1]))\n",
        "\n",
        "    # forward pass: pass the information through the layers and out the results of final output layer\n",
        "    def forward(self, input):\n",
        "        for layer in self.layers:\n",
        "            output = layer.forward(input) # because layer will give you a hidden object; then we call .forward(input) from the HiddenObject class\n",
        "            input = output\n",
        "        return output\n",
        "        pdb.set_trace()\n",
        "\n",
        "    # define the objection/loss function in last layer, we use softmax and cross-entropy as the loss\n",
        "    def delta_last_layer(self, y, y_hat, wd):\n",
        "        activation_deriv = Activation(self.activation[-1]).f_deriv\n",
        "        pdb.set_trace()\n",
        "\n",
        "        activation_deriv_wd = activation_deriv(y_hat, y) + (wd * self.layers[-1].W) # self.activation[-1] is calling the last activation used; so it's 'softmax'; calculating gradient of the loss function of the output layer that is softmax and adding penalty term\n",
        "        softmax = Activation(self.activation[-1], y).f\n",
        "        cross_entropy_loss = -np.mean(np.sum(np.log(softmax) * y, axis=1))\n",
        "        delta = activation_deriv_wd\n",
        "        return cross_entropy_loss, delta\n",
        "\n",
        "    # backward progress\n",
        "    def backward(self, delta):\n",
        "        delta = self.layers[-1].backward(delta, output_layer=True) # updating delta for the output layer; hidden-to-output weights\n",
        "        for layer in reversed(self.layers[:-1]): # now is the input-to-hidden weights\n",
        "            delta = layer.backward(delta) # this one is output_layer = False by default; therefore it is referring to the hidden layer\n",
        "\n",
        "    # update the network weights after backward.\n",
        "    # make sure you run the backward function before the update function!\n",
        "    def update(self, lr):\n",
        "        for layer in self.layers:\n",
        "            layer.W -= lr * layer.grad_W\n",
        "            layer.b -= lr * layer.grad_b\n",
        "\n",
        "    # define the training function\n",
        "    # it will return all losses within the whole training process.\n",
        "    def fit(self, X, y, learning_rate=0.1, epochs=100, weight_decay=0.01):\n",
        "\n",
        "\n",
        "        to_return = np.zeros(epochs) # loss per epoch\n",
        "\n",
        "        for k in range(epochs):\n",
        "            cross_entropy_loss_sum = 0.0 # total loss across all mini batches in the epoch\n",
        "            num_batches = 0\n",
        "            for batch_inputs, batch_targets in random_mini_batches(X, y, batchsize=256, shuffle=True): # here we are doing stochastic gradient descent (using only one example to approximate gradient and change); in the assignment need this to be mini batch GD\n",
        "\n",
        "                # forward pass\n",
        "                y_hat = self.forward(batch_inputs)\n",
        "                print(\"yhat shape:\", y_hat.shape)\n",
        "                # backward pass\n",
        "                cross_entropy_loss, delta = self.delta_last_layer(batch_targets, y_hat, weight_decay)# this calculates average loss per batch\n",
        "                self.backward(delta)\n",
        "\n",
        "                # total loss in the epoch after each mini-batch\n",
        "                cross_entropy_loss_sum += cross_entropy_loss\n",
        "                num_batches += 1\n",
        "\n",
        "                # update after each mini-batch\n",
        "                self.update(learning_rate)\n",
        "\n",
        "            to_return[k] = cross_entropy_loss_sum / num_batches\n",
        "        return to_return # returns average loss in each epoch\n",
        "\n",
        "    # define the prediction function\n",
        "    # we can use predict function to predict the results of new data, by using the well-trained network.\n",
        "    def predict(self, x):\n",
        "        x = np.array(x)\n",
        "        output = np.zeros(x.shape[0])\n",
        "        for i in np.arange(x.shape[0]):\n",
        "            output[i] = self.forward(x[i,:])\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMOISIehUJ-y"
      },
      "source": [
        "# Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "XiilBveXUJ-z"
      },
      "outputs": [],
      "source": [
        "input_n = train_data_df.shape[1] # this is 128\n",
        "output_n = len(train_label_df.iloc[:, 0].unique()) # this is 10\n",
        "nn = MLP([input_n,3,3,3,output_n], [None,'relu','relu','relu','softmax']) # MLP with 3 hidden layers, first layer is input layer which contains 2 neurons and second to fourth layers are hidden layers each containing 3 neurons and the output layer contains 10 neurons for 10 possible categories (0-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyD9d51aUJ-z",
        "outputId": "9124335b-2abc-457a-ffda-b5c123e61854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.10/bdb.py\", line 336, in set_trace\n",
            "    sys.settrace(self.trace_dispatch)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yhat shape: (256, 10)\n",
            "> \u001b[0;32m<ipython-input-69-8689fabbca70>\u001b[0m(26)\u001b[0;36mdelta_last_layer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     24 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     25 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 26 \u001b[0;31m        \u001b[0mactivation_deriv_wd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation_deriv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# self.activation[-1] is calling the last activation used; so it's 'softmax'; calculating gradient of the loss function of the output layer that is softmax and adding penalty term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     27 \u001b[0;31m        \u001b[0msoftmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     28 \u001b[0;31m        \u001b[0mcross_entropy_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> (wd * self.layers[-1].W)\n",
            "array([[-1.55842410e-03,  2.76940349e-04,  1.95585288e-03,\n",
            "         3.86684743e-03, -1.48042853e-04, -5.64623941e-07,\n",
            "        -4.60200237e-04,  1.46747011e-03, -6.83592758e-04,\n",
            "        -4.03426810e-03],\n",
            "       [-1.06401298e-03,  4.55492971e-04, -1.14353088e-03,\n",
            "        -2.82256620e-03,  6.35405309e-03, -3.65460940e-03,\n",
            "        -3.76294056e-03, -3.30295008e-03,  5.44462352e-03,\n",
            "         1.75056849e-03],\n",
            "       [-6.73503720e-03,  3.89685352e-03,  2.64356002e-03,\n",
            "        -4.93483919e-03,  1.58457023e-03, -3.96388689e-03,\n",
            "        -2.16164372e-03,  1.20054992e-03, -3.49033758e-03,\n",
            "         6.58810127e-03]])\n",
            "ipdb> (wd * self.layers[-1].W).shape\n",
            "(3, 10)\n",
            "ipdb> self.layers[-1].W\n",
            "array([[-1.55842410e-01,  2.76940349e-02,  1.95585288e-01,\n",
            "         3.86684743e-01, -1.48042853e-02, -5.64623941e-05,\n",
            "        -4.60200237e-02,  1.46747011e-01, -6.83592758e-02,\n",
            "        -4.03426810e-01],\n",
            "       [-1.06401298e-01,  4.55492971e-02, -1.14353088e-01,\n",
            "        -2.82256620e-01,  6.35405309e-01, -3.65460940e-01,\n",
            "        -3.76294056e-01, -3.30295008e-01,  5.44462352e-01,\n",
            "         1.75056849e-01],\n",
            "       [-6.73503720e-01,  3.89685352e-01,  2.64356002e-01,\n",
            "        -4.93483919e-01,  1.58457023e-01, -3.96388689e-01,\n",
            "        -2.16164372e-01,  1.20054992e-01, -3.49033758e-01,\n",
            "         6.58810127e-01]])\n",
            "ipdb> self.layers\n",
            "[<__main__.HiddenLayer object at 0x7c6d3913b850>, <__main__.HiddenLayer object at 0x7c6d6d03cf10>, <__main__.HiddenLayer object at 0x7c6d39139f90>, <__main__.HiddenLayer object at 0x7c6d39138dc0>]\n",
            "ipdb> self.layers[-1].shape\n",
            "*** AttributeError: 'HiddenLayer' object has no attribute 'shape'\n",
            "ipdb> self.layers[-1].W.shape\n",
            "(3, 10)\n"
          ]
        }
      ],
      "source": [
        "X_train = train_data_df # because the last column contains the orginaltarget values (not one-hot-vector)\n",
        "y_train = y_train_one_hot\n",
        "\n",
        "cross_entropy = nn.fit(X_train, y_train, learning_rate=0.001, epochs=500)\n",
        "# print('loss:%f'%MSE[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiSNr3O7UJ-z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}