{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP5318 Assignment 1: Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group number: 74  , SID1: 530601364 , SID2: Lee's  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a4</th>\n",
       "      <th>a5</th>\n",
       "      <th>a6</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.88</td>\n",
       "      <td>0.4874</td>\n",
       "      <td>0.541</td>\n",
       "      <td>1.515</td>\n",
       "      <td>16.55</td>\n",
       "      <td>0.3458</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.47</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>0.6721</td>\n",
       "      <td>1.919</td>\n",
       "      <td>13</td>\n",
       "      <td>0.3308</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.41</td>\n",
       "      <td>0.5879</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5082</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.41</td>\n",
       "      <td>0.5477</td>\n",
       "      <td>0.6148</td>\n",
       "      <td>2.626</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.65</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.623</td>\n",
       "      <td>3.636</td>\n",
       "      <td>28.96</td>\n",
       "      <td>?</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      a1      a2      a3     a4     a5      a6   class\n",
       "0   5.88  0.4874   0.541  1.515  16.55  0.3458  class1\n",
       "1  76.47  0.7286  0.6721  1.919     13  0.3308  class1\n",
       "2  29.41  0.5879       ?      0      0  0.5082  class1\n",
       "3  29.41  0.5477  0.6148  2.626      0  0.5365  class1\n",
       "4  17.65   0.794   0.623  3.636  28.96       ?  class2"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "breast_cancer_df = pd.read_csv(\"test-before.csv\")\n",
    "breast_cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_df = breast_cancer_df.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18068\\1402358090.py:6: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  breast_cancer_df.iloc[:, :-1] = imputer.transform(breast_cancer_df.iloc[:, :-1])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a4</th>\n",
       "      <th>a5</th>\n",
       "      <th>a6</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062078</td>\n",
       "      <td>0.499949</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>0.207933</td>\n",
       "      <td>0.259404</td>\n",
       "      <td>0.061258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.807327</td>\n",
       "      <td>0.747359</td>\n",
       "      <td>0.672100</td>\n",
       "      <td>0.263382</td>\n",
       "      <td>0.203762</td>\n",
       "      <td>0.058601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.310494</td>\n",
       "      <td>0.603036</td>\n",
       "      <td>0.418738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.310494</td>\n",
       "      <td>0.561801</td>\n",
       "      <td>0.614800</td>\n",
       "      <td>0.360417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.186339</td>\n",
       "      <td>0.814443</td>\n",
       "      <td>0.623000</td>\n",
       "      <td>0.499039</td>\n",
       "      <td>0.453918</td>\n",
       "      <td>0.159728</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.186339</td>\n",
       "      <td>0.603854</td>\n",
       "      <td>0.475400</td>\n",
       "      <td>0.152484</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.065474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.683171</td>\n",
       "      <td>0.711355</td>\n",
       "      <td>0.623000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.558910</td>\n",
       "      <td>0.525798</td>\n",
       "      <td>0.623000</td>\n",
       "      <td>0.512901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.124155</td>\n",
       "      <td>0.463945</td>\n",
       "      <td>0.557400</td>\n",
       "      <td>0.582212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100850</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.248416</td>\n",
       "      <td>0.572161</td>\n",
       "      <td>0.590200</td>\n",
       "      <td>0.651523</td>\n",
       "      <td>0.383542</td>\n",
       "      <td>0.097945</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.247044</td>\n",
       "      <td>0.499949</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>0.207933</td>\n",
       "      <td>0.259404</td>\n",
       "      <td>0.061258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.039692</td>\n",
       "      <td>0.747359</td>\n",
       "      <td>0.672100</td>\n",
       "      <td>0.263382</td>\n",
       "      <td>0.208150</td>\n",
       "      <td>0.058601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.416068</td>\n",
       "      <td>0.603036</td>\n",
       "      <td>0.418738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.690245</td>\n",
       "      <td>0.561801</td>\n",
       "      <td>0.614800</td>\n",
       "      <td>0.360417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.207454</td>\n",
       "      <td>0.814443</td>\n",
       "      <td>0.623000</td>\n",
       "      <td>0.054922</td>\n",
       "      <td>0.453918</td>\n",
       "      <td>0.083419</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.361170</td>\n",
       "      <td>0.603854</td>\n",
       "      <td>0.475400</td>\n",
       "      <td>0.152484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.711355</td>\n",
       "      <td>0.623000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104553</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.662373</td>\n",
       "      <td>0.525798</td>\n",
       "      <td>0.623000</td>\n",
       "      <td>0.902827</td>\n",
       "      <td>0.160502</td>\n",
       "      <td>0.095837</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.124155</td>\n",
       "      <td>0.463945</td>\n",
       "      <td>0.567500</td>\n",
       "      <td>0.904337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.248416</td>\n",
       "      <td>0.572572</td>\n",
       "      <td>0.590200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.574765</td>\n",
       "      <td>0.168804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.005836</td>\n",
       "      <td>0.554929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.026301</td>\n",
       "      <td>0.023614</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.005889</td>\n",
       "      <td>0.756693</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>0.012654</td>\n",
       "      <td>0.027915</td>\n",
       "      <td>0.023614</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.005412</td>\n",
       "      <td>0.689404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>0.044287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.007109</td>\n",
       "      <td>0.588573</td>\n",
       "      <td>0.232300</td>\n",
       "      <td>0.021095</td>\n",
       "      <td>0.031050</td>\n",
       "      <td>0.023614</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.004616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046520</td>\n",
       "      <td>0.011816</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a1        a2        a3        a4        a5        a6  class\n",
       "0   0.062078  0.499949  0.541000  0.207933  0.259404  0.061258      0\n",
       "1   0.807327  0.747359  0.672100  0.263382  0.203762  0.058601      0\n",
       "2   0.310494  0.603036  0.418738  0.000000  0.000000  0.090027      0\n",
       "3   0.310494  0.561801  0.614800  0.360417  0.000000  0.095040      0\n",
       "4   0.186339  0.814443  0.623000  0.499039  0.453918  0.159728      1\n",
       "5   0.186339  0.603854  0.475400  0.152484  0.100000  0.065474      1\n",
       "6   0.683171  0.711355  0.623000  0.000000  0.000000  0.087653      1\n",
       "7   0.558910  0.525798  0.623000  0.512901  0.000000  0.086856      0\n",
       "8   0.124155  0.463945  0.557400  0.582212  0.000000  0.100850      1\n",
       "9   0.248416  0.572161  0.590200  0.651523  0.383542  0.097945      0\n",
       "10  0.247044  0.499949  0.541000  0.207933  0.259404  0.061258      0\n",
       "11  0.039692  0.747359  0.672100  0.263382  0.208150  0.058601      0\n",
       "12  0.416068  0.603036  0.418738  0.000000  0.000000  0.090027      0\n",
       "13  0.690245  0.561801  0.614800  0.360417  0.000000  0.159728      0\n",
       "14  0.207454  0.814443  0.623000  0.054922  0.453918  0.083419      1\n",
       "15  0.361170  0.603854  0.475400  0.152484  1.000000  0.065474      1\n",
       "16  1.000000  0.711355  0.623000  0.000000  0.000000  0.104553      1\n",
       "17  0.662373  0.525798  0.623000  0.902827  0.160502  0.095837      0\n",
       "18  0.124155  0.463945  0.567500  0.904337  0.000000  0.119061      1\n",
       "19  0.248416  0.572572  0.590200  1.000000  0.574765  0.168804      0\n",
       "20  0.005836  0.554929  0.000000  0.001098  0.026301  0.023614      1\n",
       "21  0.005889  0.756693  0.121200  0.012654  0.027915  0.023614      1\n",
       "22  0.005412  0.689404  0.000000  0.000000  0.006834  0.044287      0\n",
       "23  0.007109  0.588573  0.232300  0.021095  0.031050  0.023614      0\n",
       "24  0.004616  0.000000  0.232300  0.000000  0.046520  0.011816      1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-process dataset\n",
    "\n",
    "# Replacing missing values with mean value of the column\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(breast_cancer_df.iloc[:, :-1])\n",
    "breast_cancer_df.iloc[:, :-1] = imputer.transform(breast_cancer_df.iloc[:, :-1])\n",
    "\n",
    "# Normalising the values between [0,1]\n",
    "breast_cancer_df.iloc[:, :-1] = MinMaxScaler().fit_transform(breast_cancer_df.iloc[:, :-1])\n",
    "\n",
    "# Changing the class values to 0 and 1 respectively\n",
    "breast_cancer_df = breast_cancer_df.replace('class1', '0')\n",
    "breast_cancer_df = breast_cancer_df.replace('class2', '1')\n",
    "breast_cancer_df[\"class\"] = breast_cancer_df[\"class\"].astype(int)\n",
    "breast_cancer_df.head(25)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0621,0.4999,0.5410,0.2079,0.2594,0.0613,0\n",
      "0.8073,0.7474,0.6721,0.2634,0.2038,0.0586,0\n",
      "0.3105,0.6030,0.4187,0.0000,0.0000,0.0900,0\n",
      "0.3105,0.5618,0.6148,0.3604,0.0000,0.0950,0\n",
      "0.1863,0.8144,0.6230,0.4990,0.4539,0.1597,1\n",
      "0.1863,0.6039,0.4754,0.1525,0.1000,0.0655,1\n",
      "0.6832,0.7114,0.6230,0.0000,0.0000,0.0877,1\n",
      "0.5589,0.5258,0.6230,0.5129,0.0000,0.0869,0\n",
      "0.1242,0.4639,0.5574,0.5822,0.0000,0.1009,1\n",
      "0.2484,0.5722,0.5902,0.6515,0.3835,0.0979,0\n"
     ]
    }
   ],
   "source": [
    "# Print first ten rows of pre-processed dataset to 4 decimal places as per assignment spec\n",
    "# A function is provided to assist\n",
    "\n",
    "x = breast_cancer_df.drop('class', axis=1).values\n",
    "y = y = breast_cancer_df['class'].values\n",
    "\n",
    "def print_data(X, y, n_rows=10):\n",
    "    \"\"\"Takes a numpy data array and target and prints the first ten rows.\n",
    "    \n",
    "    Arguments:\n",
    "        X: numpy array of shape (n_examples, n_features)\n",
    "        y: numpy array of shape (n_examples)\n",
    "        n_rows: numpy of rows to print\n",
    "    \"\"\"\n",
    "    for example_num in range(n_rows):\n",
    "        for feature in X[example_num]:\n",
    "            print(\"{:.4f}\".format(feature), end=\",\")\n",
    "\n",
    "        if example_num == len(X)-1:\n",
    "            print(y[example_num],end=\"\")\n",
    "        else:\n",
    "            print(y[example_num])\n",
    "            \n",
    "\n",
    "print_data(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Cross-validation without parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the 10 fold stratified cross-validation\n",
    "cvKFold=StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# The stratified folds from cvKFold should be provided to the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score for logistic regression: 0.6510\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def logregClassifier(X, y):\n",
    "    logreg = LogisticRegression(solver='liblinear')\n",
    "    scores = cross_val_score(logreg, X, y, cv=cvKFold)\n",
    "    return scores.mean()\n",
    "\n",
    "x = breast_cancer_df.iloc[:, :-1]\n",
    "y = breast_cancer_df.iloc[:, -1]\n",
    "\n",
    "print(\"Average cross-validation score for logistic regression: {:.4f}\".format(logregClassifier(x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score for naive bayes: 0.6555\n"
     ]
    }
   ],
   "source": [
    "#Naïve Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "def nbClassifier(X, y):\n",
    "    nb = GaussianNB()\n",
    "    scores = cross_val_score(nb, X, y, cv=cvKFold)\n",
    "    return scores.mean()\n",
    "\n",
    "x = breast_cancer_df.iloc[:, :-1]\n",
    "y = breast_cancer_df.iloc[:, -1]\n",
    "\n",
    "print(\"Average cross-validation score for naive bayes: {:.4f}\".format(nbClassifier(x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score for decision trees: 0.7752\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def dtClassifier(X, y):\n",
    "    \n",
    "    tree = DecisionTreeClassifier(criterion='entropy', random_state = 42)\n",
    "    scores = cross_val_score(tree, X, y, cv=cvKFold)\n",
    "    return scores.mean()\n",
    "\n",
    "x = breast_cancer_df.iloc[:, :-1]\n",
    "y = breast_cancer_df.iloc[:, -1]\n",
    "\n",
    "print(\"Average cross-validation score for decision trees: {:.4f}\".format(dtClassifier(x,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score for bagDTClassifier: 0.7562\n",
      "Average cross-validation score for adaDTClassifier: 0.6845\n",
      "Average cross-validation score for gbClassifier: 0.7319\n"
     ]
    }
   ],
   "source": [
    "# Ensembles: Bagging, Ada Boost and Gradient Boosting\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def bagDTClassifier(X, y, n_estimators, max_samples, max_depth):\n",
    "    bag_clt = BaggingClassifier(DecisionTreeClassifier(criterion='entropy', max_depth = max_depth, random_state=42), n_estimators = n_estimators, max_samples = max_samples)\n",
    "    scores = cross_val_score(bag_clt, X, y, cv=cvKFold)\n",
    "    return scores.mean()\n",
    "\n",
    "def adaDTClassifier(X, y, n_estimators, learning_rate, max_depth):\n",
    "    ada_clt = AdaBoostClassifier(DecisionTreeClassifier(criterion='entropy', max_depth=max_depth), n_estimators = n_estimators, learning_rate = learning_rate, random_state=42)\n",
    "    scores = cross_val_score(ada_clt, X, y, cv=cvKFold)\n",
    "    return scores.mean()\n",
    "\n",
    "def gbClassifier(X, y, n_estimators, learning_rate):\n",
    "    gb_clt = GradientBoostingClassifier(n_estimators = n_estimators, learning_rate = learning_rate)\n",
    "    scores = cross_val_score(gb_clt, X, y, cv=cvKFold)\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "x = breast_cancer_df.iloc[:, :-1]\n",
    "y = breast_cancer_df.iloc[:, -1]\n",
    "\n",
    "print(\"Average cross-validation score for bagDTClassifier: {:.4f}\".format(bagDTClassifier(x,y, n_estimators = 500, max_samples = 100, max_depth = 10)))\n",
    "print(\"Average cross-validation score for adaDTClassifier: {:.4f}\".format(adaDTClassifier(x,y, n_estimators = 200, learning_rate = 0.5, max_depth = 10)))\n",
    "print(\"Average cross-validation score for gbClassifier: {:.4f}\".format(gbClassifier(x,y, n_estimators = 200, learning_rate = 0.2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogR average cross-validation accuracy: 0.6510\n",
      "NB average cross-validation accuracy: 0.6555\n",
      "DT average cross-validation accuracy: 0.7752\n",
      "Bagging average cross-validation accuracy 0.7657\n",
      "AdaBoost average cross-validation accuracy: 0.7512\n",
      "GB average cross-validation accuracy: 0.7464\n"
     ]
    }
   ],
   "source": [
    "# Parameters for Part 1:\n",
    "\n",
    "#Bagging\n",
    "bag_n_estimators = 60\n",
    "bag_max_samples = 100\n",
    "bag_max_depth = 6\n",
    "\n",
    "#AdaBoost\n",
    "ada_n_estimators = 60\n",
    "ada_learning_rate = 0.5\n",
    "ada_bag_max_depth = 6\n",
    "\n",
    "#GB\n",
    "gb_n_estimators = 60\n",
    "gb_learning_rate = 0.5\n",
    "\n",
    "x = breast_cancer_df.iloc[:, :-1]\n",
    "y = breast_cancer_df.iloc[:, -1]\n",
    "\n",
    "# Print results for each classifier in part 1 to 4 decimal places here:\n",
    "print(\"LogR average cross-validation accuracy: {:.4f}\".format(logregClassifier(x, y)))\n",
    "print(\"NB average cross-validation accuracy: {:.4f}\".format(nbClassifier(x, y)))\n",
    "print(\"DT average cross-validation accuracy: {:.4f}\".format(dtClassifier(x, y)))\n",
    "print(\"Bagging average cross-validation accuracy {:.4f}\".format(bagDTClassifier(x, y, bag_n_estimators, bag_max_samples, bag_max_depth)))\n",
    "print(\"AdaBoost average cross-validation accuracy: {:.4f}\".format(adaDTClassifier(x, y, ada_n_estimators, ada_learning_rate, ada_bag_max_depth)))\n",
    "print(\"GB average cross-validation accuracy: {:.4f}\".format(gbClassifier(x, y, gb_n_estimators, gb_learning_rate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Cross-validation with parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 0.7329166666666668, KNeighborsClassifier(n_neighbors=1, p=1))\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "k = [1, 3, 5, 7, 9]\n",
    "p = [1, 2]\n",
    "param_grid = {'n_neighbors': k,\n",
    "              'p': p}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def bestKNNClassifier(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=0)\n",
    "\n",
    "    grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=cvKFold,\n",
    "                          return_train_score=True)\n",
    "\n",
    "\n",
    "    grid_search.fit(X_train, y_train) #doing 5 by 2 by 10 total runs    \n",
    "    \n",
    "    test_set_score = grid_search.score(X_test, y_test)\n",
    "    best_params = grid_search.best_params_\n",
    "    best_cross_validation_score = grid_search.best_score_\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    return best_params['n_neighbors'], best_params['p'], best_cross_validation_score, best_estimator  #(appropriate values so that the required printing can be done)\n",
    "\n",
    "x = breast_cancer_df.iloc[:, :-1]\n",
    "y = breast_cancer_df.iloc[:, -1]\n",
    "\n",
    "print(bestKNNClassifier(x,y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "# You should use SVC from sklearn.svm with kernel set to 'rbf'\n",
    "C = [0.01, 0.1, 1, 5, 15] \n",
    "gamma = [0.01, 0.1, 1, 10, 50]\n",
    "\n",
    "def bestSVMClassifier(X, y):\n",
    "    \n",
    "    return  #(appropriate values so that the required printing can be done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 18, 0.8074999999999999, 0.6792452830188679, RandomForestClassifier(max_leaf_nodes=18, n_estimators=150), '0.67', '0.68')\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "# You should use RandomForestClassifier from sklearn.ensemble with information gain and max_features set to ‘sqrt’.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import *\n",
    "import pandas as pd\n",
    "\n",
    "n_estimators = [10, 30, 60, 100, 150]\n",
    "max_leaf_nodes = [6, 12, 18]\n",
    "param_grid = {'n_estimators': [10, 30, 60, 100, 150], \n",
    "              'max_leaf_nodes': [6, 12, 18]}\n",
    "\n",
    "def bestRFClassifier(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, random_state=0\n",
    "    )\n",
    "\n",
    "    grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=cvKFold,\n",
    "                               return_train_score=True)\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    test_set_score = grid_search.score(X_test, y_test)\n",
    "    best_params = grid_search.best_params_\n",
    "    best_cross_validation_score = grid_search.best_score_\n",
    "    best_esimator = grid_search.best_estimator_\n",
    "    actual = y_test\n",
    "\n",
    "    RF = RandomForestClassifier()\n",
    "    RF.fit(X_train, y_train)\n",
    "    actual = y_test\n",
    "    predicted = RF.predict(X_test)\n",
    "    lst = metrics.classification_report(actual, predicted)\n",
    "    lst = lst.split()\n",
    "    df = pd.Series(lst)\n",
    "    return best_params['n_estimators'], best_params['max_leaf_nodes'], best_cross_validation_score, test_set_score, best_esimator, df[21], df[27]#(appropriate values so that the required printing can be done)\n",
    "    # two more values, the marco average F1 score and the weighted average F1 score.\n",
    "x = breast_cancer_df.iloc[:, :-1]\n",
    "y = breast_cancer_df.iloc[:, -1]\n",
    "\n",
    "print(bestRFClassifier(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'max_leaf_nodes' for estimator KNeighborsClassifier(). Valid parameters are: ['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m x \u001b[39m=\u001b[39m breast_cancer_df\u001b[39m.\u001b[39miloc[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m      9\u001b[0m y \u001b[39m=\u001b[39m breast_cancer_df\u001b[39m.\u001b[39miloc[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m---> 11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mKNN best k: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(bestKNNClassifier(x, y)[\u001b[39m0\u001b[39m]))\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mKNN best p: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(bestKNNClassifier(x, y)[\u001b[39m1\u001b[39m]))\n\u001b[0;32m     13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mKNN cross-validation accuracy: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(bestKNNClassifier(x, y)[\u001b[39m2\u001b[39m]))\n",
      "Cell \u001b[1;32mIn[87], line 18\u001b[0m, in \u001b[0;36mbestKNNClassifier\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     11\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(\n\u001b[0;32m     12\u001b[0m X, y, stratify\u001b[39m=\u001b[39my, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     14\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(KNeighborsClassifier(), param_grid, cv\u001b[39m=\u001b[39mcvKFold,\n\u001b[0;32m     15\u001b[0m                       return_train_score\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 18\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train) \u001b[39m#doing 5 by 2 by 10 total runs    \u001b[39;00m\n\u001b[0;32m     20\u001b[0m test_set_score \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mscore(X_test, y_test)\n\u001b[0;32m     21\u001b[0m best_params \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\myenvv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\myenvv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\myenvv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\myenvv\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\myenvv\\lib\\site-packages\\joblib\\parallel.py:1048\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1040\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1048\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1049\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\myenvv\\lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    865\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\myenvv\\lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    783\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\myenvv\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\myenvv\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\myenvv\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\myenvv\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\myenvv\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\myenvv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:674\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m parameters\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    672\u001b[0m         cloned_parameters[k] \u001b[39m=\u001b[39m clone(v, safe\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 674\u001b[0m     estimator \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcloned_parameters)\n\u001b[0;32m    676\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    678\u001b[0m X_train, y_train \u001b[39m=\u001b[39m _safe_split(estimator, X, y, train)\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\myenvv\\lib\\site-packages\\sklearn\\base.py:205\u001b[0m, in \u001b[0;36mBaseEstimator.set_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m valid_params:\n\u001b[0;32m    204\u001b[0m     local_valid_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_param_names()\n\u001b[1;32m--> 205\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    206\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid parameter \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m!r}\u001b[39;00m\u001b[39m for estimator \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    207\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValid parameters are: \u001b[39m\u001b[39m{\u001b[39;00mlocal_valid_params\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m     )\n\u001b[0;32m    210\u001b[0m \u001b[39mif\u001b[39;00m delim:\n\u001b[0;32m    211\u001b[0m     nested_params[key][sub_key] \u001b[39m=\u001b[39m value\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'max_leaf_nodes' for estimator KNeighborsClassifier(). Valid parameters are: ['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights']."
     ]
    }
   ],
   "source": [
    "# Perform Grid Search with 10-fold stratified cross-validation (GridSearchCV in sklearn). \n",
    "# The stratified folds from cvKFold should be provided to GridSearchV\n",
    "\n",
    "# This should include using train_test_split from sklearn.model_selection with stratification and random_state=0\n",
    "# Print results for each classifier here. All results should be printed to 4 decimal places except for\n",
    "# \"k\", \"p\", n_estimators\" and \"max_leaf_nodes\" which should be printed as integers.\n",
    "\n",
    "x = breast_cancer_df.iloc[:, :-1]\n",
    "y = breast_cancer_df.iloc[:, -1]\n",
    "\n",
    "print(\"KNN best k: {}\".format(bestKNNClassifier(x, y)[0]))\n",
    "print(\"KNN best p: {}\".format(bestKNNClassifier(x, y)[1]))\n",
    "print(\"KNN cross-validation accuracy: {:.4f}\".format(bestKNNClassifier(x, y)[2]))\n",
    "print(\"KNN test set accuracy: {}\".format(bestKNNClassifier(x, y)[3]))\n",
    "\n",
    "# print()\n",
    "\n",
    "# print(\"SVM best C: \")\n",
    "# print(\"SVM best gamma: \")\n",
    "# print(\"SVM cross-validation accuracy: \")\n",
    "# print(\"SVM test set accuracy: \")\n",
    "\n",
    "# print()\n",
    "\n",
    "# print(\"RF best n_estimators: \")\n",
    "# print(\"RF best max_leaf_nodes: \")\n",
    "# print(\"RF cross-validation accuracy: \")\n",
    "# print(\"RF test set accuracy: \")\n",
    "# print(\"RF test set macro average F1: \")\n",
    "# print(\"RF test set weighted average F1: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
